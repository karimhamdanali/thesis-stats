...
running Spark for dacapo/bloat
Loading properties...
Generating the call graph from Spark.

Preparing classes ...
Adding application archive: /u4/karim/workspace/thesis-stats/benchmarks-averroes/dacapo/bloat-organized-app.jar
Adding placeholder library archive: /u4/karim/workspace/thesis-stats/benchmarks-averroes/dacapo/bloat-organized-lib.jar
[Call Graph] For information on where the call graph may be incomplete, use the verbose option to the cg phase.
Total methods: 21310
Initially reachable methods: 8
Classes with at least one reachable method: 3
[Spark] Pointer Assignment Graph in 0.2 seconds.
Total types: 2468
[Spark] Type masks in 0.0 seconds.
VarNodes: 18
FieldRefNodes: 1
AllocNodes: 5
Cleaning up graph for merged nodes
Done cleaning up graph for merged nodes
[Spark] Pointer Graph simplified in 0.0 seconds.
Worklist has 5 nodes.
Now handling field references
Worklist has 3057 nodes.
Now handling field references
Worklist has 3075 nodes.
Now handling field references
Worklist has 3867 nodes.
Now handling field references
Worklist has 3438 nodes.
Now handling field references
Worklist has 3947 nodes.
Now handling field references
Worklist has 1923 nodes.
Now handling field references
Worklist has 956 nodes.
Now handling field references
Worklist has 154 nodes.
Now handling field references
Worklist has 49 nodes.
Now handling field references
[Spark] Propagation in 40.6 seconds.
[Spark] Solution found in 41.6 seconds.
[Spark] Number of reachable methods: 11533
size of original spark is: 68946
Total time to finish: 52.15
=================================================
# edges = 14514
=================================================

elapsed time: 60.02s
